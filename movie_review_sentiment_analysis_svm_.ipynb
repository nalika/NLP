{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "movie_review_sentiment_analysis_svm .ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nalika/NLP/blob/master/movie_review_sentiment_analysis_svm_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_LBYc6quwmM",
        "colab_type": "text"
      },
      "source": [
        "**NOTE:**\n",
        "1. We’ll use libraries from the Natural Language Toolkit (NLTK). This is a very popular NLP library for Python.\n",
        "2. Classifying IMDb Movie Reviews"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PoH_HqznvQwx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Install NLTK\n",
        "!pip install -q  nltk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sR829gMxezI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "08400a84-94ca-4663-a8d9-346961a57485"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords') #Resource stopwords"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHBom0MwDfAk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "6a6a5894-dd7c-49f0-aa82-a86ea0024ec2"
      },
      "source": [
        "# import data\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6hs-hUdD3hc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import zipfile # to unzip\n",
        "import tarfile\n",
        "\n",
        "fname = 'gdrive/My Drive/Colab Notebooks/aclImdb_v1.tar.gz'\n",
        "\n",
        "\n",
        "if (fname.endswith(\"tar.gz\")):\n",
        "    tar = tarfile.open(fname, \"r:gz\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "elif (fname.endswith(\"tar\")):\n",
        "    tar = tarfile.open(fname, \"r:\")\n",
        "    tar.extractall()\n",
        "    tar.close()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akxI_PwqGFqF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "python3 -m tarfile -e fname  '/content/gdrive'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c9IZA4KFFHIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews_train = []\n",
        "for line in open('full_train.txt', 'r'):\n",
        "    reviews_train.append(line.strip())\n",
        "    \n",
        "reviews_test = []\n",
        "for line in open('tar/full_test.txt', 'r'):\n",
        "    reviews_test.append(line.strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mU7e5FJdsyXB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "\n",
        "english_stop_words = stopwords.words('english')\n",
        "def remove_stop_words(corpus):\n",
        "    removed_stop_words = []\n",
        "    for review in corpus:\n",
        "        removed_stop_words.append(\n",
        "            ' '.join([word for word in review.split() \n",
        "                      if word not in english_stop_words])\n",
        "        )\n",
        "    return removed_stop_words\n",
        "\n",
        "no_stop_words = remove_stop_words(reviews_train_clean)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aK2XKPOzZ2u-",
        "colab_type": "text"
      },
      "source": [
        "## **NOTE**: This extract is taken from Python Machine Learning Cookbook by Prateek Joshi.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpMjemumf3bG",
        "colab_type": "text"
      },
      "source": [
        "Step 1: Create a new Python file, and import the following packages:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kw3vdKImXbq7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0bb9a860-ee28-4777-acf6-afd4446eb32c"
      },
      "source": [
        "import nltk.classify.util\n",
        "from nltk.classify import NaiveBayesClassifier\n",
        "#from nltk.corpus import movie_reviews\n",
        "nltk.download('movie_reviews') # corpus"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/movie_reviews.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uzghmUCCf-3d",
        "colab_type": "text"
      },
      "source": [
        "Step 2: Define a function to extract features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svz9E3sBXhOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract_features(word_list):\n",
        "  return dict([(word, True) for word in word_list])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM5xljy2gEM6",
        "colab_type": "text"
      },
      "source": [
        "Step 3: We need training data for this, so we will use movie reviews in NLTK:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6xR59hcXzZW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "positive_fileids = movie_reviews.fileids('pos') # Load positive reviews  \n",
        "negative_fileids = movie_reviews.fileids('neg') # Load negative reviews  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NfihSRQPgJrT",
        "colab_type": "text"
      },
      "source": [
        "Step 4: Let’s separate these into positive and negative reviews:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ztblp0wSY7YU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features_positive = [(extract_features(movie_reviews.words(fileids=[f])), \n",
        "           'Positive') for f in positive_fileids]\n",
        "features_negative = [(extract_features(movie_reviews.words(fileids=[f])), \n",
        "           'Negative') for f in negative_fileids]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kKm0LfYUgMGY",
        "colab_type": "text"
      },
      "source": [
        "Step 5: Divide the data into training and testing datasets:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idNS5WgDay31",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold_factor = 0.8 Split the data into train and test (80/20)\n",
        "threshold_positive = int(threshold_factor * len(features_positive))\n",
        "threshold_negative = int(threshold_factor * len(features_negative))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m5Zcef0egQQP",
        "colab_type": "text"
      },
      "source": [
        "Step 6: Extract the features:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RN2oGR6a1e6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "0bb9083f-b1f0-47be-bf92-e46dbd13cafa"
      },
      "source": [
        "features_train = features_positive[:threshold_positive] + features_negative[:threshold_negative]\n",
        "features_test = features_positive[threshold_positive:] + features_negative[threshold_negative:]  \n",
        "\n",
        "print (\"\\nNumber of training datapoints:\", len(features_train))\n",
        "print (\"Number of test datapoints:\", len(features_test))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Number of training datapoints: 1600\n",
            "Number of test datapoints: 400\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGxRsKdBgUc-",
        "colab_type": "text"
      },
      "source": [
        "Step 7: Train a model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cR9Rno3za1v8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "ab4fa670-c79a-4c8f-846b-66d606c4347b"
      },
      "source": [
        "# Note: We will use a Naive Bayes classifier. Define the object and train it.\n",
        "classifier = NaiveBayesClassifier.train(features_train)\n",
        "print (\"\\nAccuracy of the classifier:\", \n",
        "       nltk.classify.util.accuracy(classifier, features_test))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Accuracy of the classifier: 0.735\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYX445xMgc-O",
        "colab_type": "text"
      },
      "source": [
        "Step 8: Sanity check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHljCuBWbjet",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "bf19ce32-957e-4541-c8eb-e05b12039636"
      },
      "source": [
        "# The classifier object contains the most informative words that it \n",
        "# obtained during analysis. These words basically have a strong say in what’s \n",
        "# classified as a positive or a negative review. Let’s print them out:\n",
        "print (\"\\nTop 10 most informative words:\")\n",
        "for item in classifier.most_informative_features()[:10]:\n",
        "  print (item[0])"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Top 10 most informative words:\n",
            "outstanding\n",
            "insulting\n",
            "vulnerable\n",
            "ludicrous\n",
            "uninvolving\n",
            "avoids\n",
            "astounding\n",
            "fascination\n",
            "animators\n",
            "anna\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vaOUMxdFglIa",
        "colab_type": "text"
      },
      "source": [
        " Step 9: Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTDGzIrIcIPN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a couple of random input sentences:\n",
        "# Sample input reviews\n",
        "input_reviews = [\n",
        "       \"It is an amazing movie\", \n",
        "       \"This is a dull movie. I would never recommend it to anyone.\",\n",
        "       \"The cinematography is pretty great in this movie\", \n",
        "       \"The direction was terrible and the story was all over the place\" \n",
        "]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CIvqbbOMgrre",
        "colab_type": "text"
      },
      "source": [
        "Step 10: Test the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bhu9HacSYqrC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "debb537a-d42a-4dea-e417-a399e0a80b37"
      },
      "source": [
        "# Run the classifier on those input sentences and obtain the predictions:\n",
        "from termcolor import colored\n",
        "\n",
        "print (\"\\nPredictions:\\n\",30*\"-\")\n",
        "for review in input_reviews:\n",
        "    print (\"\\nReview:\", review)\n",
        "    probdist = classifier.prob_classify(extract_features(review.split()))\n",
        "    pred_sentiment = probdist.max()\n",
        "    \n",
        "    # Step 11: Print the output:\n",
        "    if pred_sentiment == \"Positive\":      \n",
        "      print(\"Predicted sentiment:\", colored(pred_sentiment, 'green'))\n",
        "    else:\n",
        "      print(\"Predicted sentiment:\", colored(pred_sentiment, 'red'))\n",
        "    print (\"Probability:\", round(probdist.prob(pred_sentiment), 2))\n",
        "      \n",
        "\n",
        "\n"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Predictions:\n",
            " ------------------------------\n",
            "\n",
            "Review: It is an amazing movie\n",
            "Predicted sentiment: \u001b[32mPositive\u001b[0m\n",
            "Probability: 0.61\n",
            "\n",
            "Review: This is a dull movie. I would never recommend it to anyone.\n",
            "Predicted sentiment: \u001b[31mNegative\u001b[0m\n",
            "Probability: 0.77\n",
            "\n",
            "Review: The cinematography is pretty great in this movie\n",
            "Predicted sentiment: \u001b[32mPositive\u001b[0m\n",
            "Probability: 0.67\n",
            "\n",
            "Review: The direction was terrible and the story was all over the place\n",
            "Predicted sentiment: \u001b[31mNegative\u001b[0m\n",
            "Probability: 0.63\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}